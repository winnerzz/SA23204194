---
title: "Introduction to R-package"
author: "Xu Tongzhou"
date: "2023-11-27"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to R-package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

 __SA23204194__ is a R package to implement algorithms and example functions for K-means
 and newtonMethod and provid Rcpp version (implemented through the R package _Rcpp_). 
 Two functions are considered, namely, _kmeans_ () and _newtonMethod_ ().
 For each function, both R and Rcpp versions are produced. Namely _kmeansR_ and 
 _newtonMethodR_ for R and _kmeansC_ and _newtonMethodC_ for C++.
 The R package 'microbenchmark' can be used to benchmark the above R and C++ functions.


## Benchmarking _kmeansR_ and _kmeansC_


### K-means clustering 
 a popular unsupervised machine learning algorithm used for clustering data into a predefined number of groups (k). 
 It aims to partition the data into k clusters in which each data point belongs to the cluster with the nearest mean, serving as a prototype of the cluster.

### workflow:
Initialization: Randomly selects k data points as initial cluster centers.
Assignment: Assigns each data point to the nearest cluster center based on Euclidean distance.
Update: Updates each cluster center by calculating the mean of all data points assigned to the cluster.
Convergence: Repeats the assignment and update steps until the cluster centers no longer change significantly or a maximum number of iterations is reached.

### The source R code for _kmeansR_ is as follows:
```{r,eval=FALSE}
 function(data, k, max.iter = 100) {
  #   Initialize cluster center
  centers <- data[sample(nrow(data), k), ]
  #  Initialize cluster allocation
  clusters <- numeric(nrow(data))
  
  for (iter in 1:max.iter) {
    # Assign data points to the nearest cluster center
    for (i in 1:nrow(data)) {
      min.dist <- Inf
      for (j in 1:k) {
        dist <- sum((data[i, ] - centers[j, ])^2)
        if (dist < min.dist) {
          min.dist <- dist
          clusters[i] <- j
        }
      }
    }
# Update cluster center
 new.centers <- centers
for (j in 1:k) {
cluster.data <- data[clusters == j, ]
if (nrow(cluster.data) > 0) {
new.centers[j, ] <- colMeans(cluster.data)
}
}
 #  Check convergence
if (all(new.centers == centers)) {
break
}
centers <- new.centers
}
list(centers = centers, clusters = clusters)
}
```

### The source Rcpp code for _kmeansC_ is as follows:
```{r,eval=FALSE}
List kmeansC(NumericMatrix data, int k, int maxIter = 100) {
   int n = data.nrow(), d = data.ncol();
   NumericMatrix centers(k, d);
   IntegerVector clusters(n, 0);
   bool change = true;
   int iter = 0;
   
   // Initialize cluster center
   IntegerVector center_indices = Rcpp::sample(n, k, false) - 1; // 减1以适应C++的0索引
   for (int i = 0; i < k; ++i) {
     centers(i, _) = data(center_indices[i], _);
   }
   
   // Iteration until convergence or maximum number of iterations reached
   while (change && iter < maxIter) {
     change = false;
     ++iter;
     
     // Assign data points to the nearest center point
     for (int i = 0; i < n; ++i) {
       double minDist = R_PosInf;
       int bestCluster = 0;
       for (int j = 0; j < k; ++j) {
         double dist = sqrt(sum(pow(data(i,_) - centers(j,_), 2)));
         if (dist < minDist) {
           minDist = dist;
           bestCluster = j;
         }
       }
       if (clusters[i] != bestCluster) {
         clusters[i] = bestCluster;
         change = true;
       }
     }
     
     //  Update center point
     if (change) {
       NumericMatrix newCenters(k, d);
       IntegerVector counts(k, 0);
       for (int i = 0; i < n; ++i) {
         int cluster = clusters[i];
         counts[cluster]++;
         for (int j = 0; j < d; ++j) {
           newCenters(cluster, j) += data(i, j);  // Accumulate all dimensions
       }
       for (int j = 0; j < k; ++j) {
         if (counts[j] > 0) {
           for (int col = 0; col < d; ++col) {
             centers(j, col) = newCenters(j, col) / counts[j];
           }
         }
       }
     }
   
   return List::create(Named("centers") = centers, Named("clusters") = clusters);
 }
}
```

### The R code for benchmark _kmeansR_ and _kmeansC_  is as follows.
```{r,eval=FALSE}
library(SA23204194)
library(microbenchmark)
set.seed(123)
data <- matrix(rnorm(100), ncol = 2)
 kmeans_custom(data, 3)
 tm <- microbenchmark(
  R = kmeansR(data,3),
  Rcpp = kmeansC(data,3)
  times = 1000
)
```

### The above results show an evident computational speed gain of C++ against R.

### Usage Guidelines
Use when you have unlabeled data and want to identify inherent groupings.
Choose k carefully; too many or too few clusters can lead to poor results.
Initial cluster centers can significantly affect the final clusters.
Consider standardizing data, especially when variables are on different scales.

## Benchmarking _newtonMethodR_ and _newtonMethodC_


### Newton's method 
also known as the Newton-Raphson method is a root-finding algorithm that produces successively better approximations to the roots (or zeroes) of a real-valued function.


### workflow:
Initialization: Starts with an initial guess.
Iteration: Applies the Newton's update formula: x_new = x_old - f(x_old) / f'(x_old).
Convergence: Continues iterations until the change in x is less than a tolerance level or a maximum number of iterations is reached.


### The source R code for _newtonMethodR_ is as follows:
```{r,eval=FALSE}
function(f, df, x0, maxiter = 100, tol = 1e-6) {
  x <- x0
  for (iter in 1:maxiter) {
    fx <- f(x)
    dfx <- df(x)
    
    if (abs(dfx) < .Machine$double.eps) {
      stop("Derivative is zero. No solution found.")
    }
    
    x_new <- x - fx / dfx
    if (abs(x_new - x) < tol) {
      return(x_new)
    }
    
    x <- x_new
  }
  stop("Maximum iterations reached. No solution found.")
}
```

### The source Rcpp code for _newtonMethodC_ is as follows:
```{r,eval=FALSE}
double newtonMethodC(Function f, Function df, double x0, int maxiter = 100, double tol = 1e-6) {
  double x = x0;
  double fx = Rcpp::as<double>(f(x));
  double dfx;
  int iter = 0;
  
  while (std::abs(fx) > tol && iter < maxiter) {
    dfx = Rcpp::as<double>(df(x));
    if (dfx == 0) {
      stop("Derivative is zero. No solution found.");
    }
    
    x = x - fx / dfx;
    fx = Rcpp::as<double>(f(x));
    iter++;
  }
  
  if (std::abs(fx) > tol) {
    stop("Maximum iterations reached. No solution found.");
  }
  
  return x;
}
```
### The R code for benchmark _newtonMethodR_ and _newtonMethodC_  is as follows.
```{r,eval=FALSE}
library(SA23204194)
library(microbenchmark)
 kmeans_custom(data, 3)
 ts <- microbenchmark(
  R = newtonMethodR(f,df,x0=1.5),
  Rcpp = newtonMethodC(f,df,x0=1.5)
  times = 1000
)
```
### The results again show an evident computational speed gain of C++ against R.

### usage Guideline:
Use when you need to find roots of a non-linear equation efficiently.
Requires a good initial guess to converge to the correct root.
The function should be differentiable, and its derivative should not be zero at the root.
Be cautious with functions that have steep slopes or multiple roots.